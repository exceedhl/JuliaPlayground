using Distributions
using LineSearches, Optim

include("util.jl")

mutable struct BasicNN
    Ln::Array{Unsigned, 1}
    L
    ğš¯
    Î»::Float64

    function BasicNN(Ln, Î»=1)
        L = []
        for i in 1:(length(Ln) - 1)
            push!(L, [Ln[i+1], Ln[i] + 1])
        end
        ğš¯ = init_Î¸(L)
        new(Ln, L, ğš¯, Î»)
    end
end

function init_Î¸(L)
    Ïµ = 0.12
    init_Î¸ = rand(Distributions.Uniform(-Ïµ, Ïµ), mapreduce(prod, +, L))
    vector_to_array(init_Î¸, L)
end

sigmoid(z) = 1.0 ./ (1.0 + exp(-z))

function H(x, ğš¯) # refactor to support more layers
    Î¸1, Î¸2 = ğš¯
    a1 = x
    a2 = sigmoid.(Î¸1 * [1; x])
    a3 = sigmoid.(Î¸2 * [1; a2])
    [a1, a2, a3]
end

function cost(a, y)
    -log.(a[end])' * y - log.(1 .- a[end])' * (1 .- y)
end

function J(nn::BasicNN, X_train, Y_train)
    Î¸1, Î¸2 = nn.ğš¯
    C = 0
    for i = 1:m
        x = X_train[i, :]
        y = Y_train[i]
        a = H(x, nn.ğš¯)
        C += cost(a, y)
    end
    C = C / m + (sum(Î¸1[:, 2:end] .^ 2) + sum(Î¸2[:, 2:end] .^ 2)) * Î» / (2 * m)
end

function Î”ğš¯(a, y, ğš¯) # refactor to support more layers
    a1, a2, a3 = a
    Î¸1, Î¸2 = ğš¯
    Î´3 = (a3 - y)
    Î´2 = (Î¸2'*Î´3)[2:end] .* (a2 .* (1 .- a2))
    [Î´2 * [1; a1]', Î´3 * [1; a2]']
end

function Î”J(nn::BasicNN, X_train, Y_train)
    Î”ğš¯s = map(l->zeros(l...), nn.L)
    for i = 1:m
        x = X_train[i, :]
        y = Y_train[i]
        a = H(x, nn.ğš¯)
        Î”ğš¯s += Î”ğš¯(a, y, nn.ğš¯)
    end
    Î”ğš¯s /= m
    for i = 1:length(Î”ğš¯s)
        Î”ğš¯s[i][:, 2:end] += Î» * nn.ğš¯[i][:, 2:end] / m
    end
    Î”ğš¯s
end

function train!(nn::BasicNN, X_train, Y_train; Î» = 1, iterations = 50)
    # update nn's Î» if provided
    nn.Î» = Î»

    # use Optim to find minimum ğš¯
    function f(Î¸_vec)
        nn.ğš¯ = vector_to_array(Î¸_vec, nn.L)
        J(nn, X_train, Y_train)
    end

    function g!(storage, Î¸_vec)
        nn.ğš¯ = vector_to_array(Î¸_vec, nn.L)
        g = array_to_vector(Î”J(nn, X_train, Y_train))
        for i = 1:length(storage)
            storage[i] = g[i]
        end
    end

    @time @show result = Optim.optimize(
        f,
        g!,
        array_to_vector(nn.ğš¯),
        LBFGS(m=5, alphaguess=LineSearches.InitialHagerZhang(), linesearch=LineSearches.MoreThuente()),
        # LBFGS(m=20, alphaguess=LineSearches.InitialQuadratic(), linesearch = LineSearches.StrongWolfe()),
        Optim.Options(iterations = iterations, show_trace=true, show_every=1)
        # ConjugateGradient()
        # ConjugateGradient(eta=0.1, alphaguess=LineSearches.InitialQuadratic(), linesearch = LineSearches.StrongWolfe())
    )
    ğš¯_min = vector_to_array(result.minimizer, nn.L)
    nn.ğš¯ = ğš¯_min
end

function predict(nn::BasicNN, x)
    H(x, nn.ğš¯)[end]
end
