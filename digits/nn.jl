using Plots, Images, CSV, DataFrames
using Distributions
using Optim
using Test

d = CSV.read("./digits/train.csv")
X = convert(Array, d[!, 2:end] ./ 255)

function transform_digit_to_bitvec(digit, levels)
    vec = zeros(levels)
    setindex!(vec, 1, digit + 1)
    return vec
end

function transform_bitvec_to_digit(vec)
    findmax(vec)[2] - 1
end

Y = map(x->transform_digit_to_bitvec(x, 10), d[!, 1])

m = 40000
X_train = X[1:m, :]
Y_train = Y[1:m]

sigmoid(z) = 1.0 ./ (1.0 + exp(-z))

function H(x, ğš¯)
    Î¸1, Î¸2 = ğš¯
    a1 = x
    a2 = sigmoid.(Î¸1 * [1; x])
    a3 = sigmoid.(Î¸2 * [1; a2])
    [a1, a2, a3]
end

function cost(a, y)
    a1, a2, a3 = a
    -log.(a3)' * y - log.(1 .- a3)' * (1 .- y)
end

function J(ğš¯)
    Î¸1, Î¸2 = ğš¯
    C = 0
    for i = 1:m
        x = X_train[i, :]
        y = Y_train[i]
        a = H(x, ğš¯)
        C += cost(a, y)
    end
    C = C / m + (sum(Î¸1[:, 2:end] .^ 2) + sum(Î¸2[:, 2:end] .^ 2)) * Î» / (2 * m)
end

function Î”ğš¯(a, y, ğš¯)
    a1, a2, a3 = a
    Î¸1, Î¸2 = ğš¯
    Î´3 = (a3 - y)
    Î´2 = (Î¸2'*Î´3)[2:end] .* (a2 .* (1 .- a2))
    [Î´2 * [1; a1]', Î´3 * [1; a2]']
end

function Î”J(ğš¯)
    Î”ğš¯s = map(Î¸->zeros(size(Î¸)), ğš¯)
    for i = 1:m
        x = X_train[i, :]
        y = Y_train[i]
        a = H(x, ğš¯)
        Î”ğš¯s += Î”ğš¯(a, y, ğš¯)
    end
    Î”ğš¯s /= m
    for i = 1:length(Î”ğš¯s)
        Î”ğš¯s[i][:, 2:end] += Î» * ğš¯[i][:, 2:end] / m
    end
    Î”ğš¯s
end

function predict(x, ğš¯)
    a1, a2, a3 = H(x,ğš¯)
    transform_bitvec_to_digit(a3)
end

L1 = 784
L2 = 50
L3 = 10
Î» = 1

Ïµ = 0.12
init_Î¸1 = reshape(
    rand(Distributions.Uniform(-Ïµ, Ïµ), (L1 + 1) * L2),
    L2,
    (L1 + 1),
) # L2 x L1
init_Î¸2 = reshape(
    rand(Distributions.Uniform(-Ïµ, Ïµ), (L2 + 1) * L3),
    L3,
    (L2 + 1),
) # L3 x L2


# use Optim to find minimum ğš¯
function array_to_vector(arr)
    mapreduce(x -> reshape(x, length(x)), vcat, arr, init = Float64[])
end

function vector_to_array(v, dims = [(L2, (L1 + 1)), (L3, (L2 + 1))])
    result = []
    i = 1
    for dim in dims
        push!(result, reshape(v[i:i+dim[1]*dim[2]-1], dim...))
        i += prod(dim)
    end
    result
end

@test array_to_vector([init_Î¸1, init_Î¸2]) ==
    array_to_vector(vector_to_array(array_to_vector([init_Î¸1, init_Î¸2])))

function f(Î¸_vec)
    J(vector_to_array(Î¸_vec))
end

function g!(storage, Î¸_vec)
    g = array_to_vector(Î”J(vector_to_array(Î¸_vec)))
    for i = 1:length(storage)
        storage[i] = g[i]
    end
end

#=
using LineSearches
@time @show result = Optim.optimize(
    f,
    g!,
    array_to_vector([init_Î¸1, init_Î¸2]),
    LBFGS(m=5, alphaguess=LineSearches.InitialHagerZhang(), linesearch=LineSearches.MoreThuente()),
    # LBFGS(m=20, alphaguess=LineSearches.InitialQuadratic(), linesearch = LineSearches.StrongWolfe()),
    Optim.Options(iterations = 10, show_trace=true, show_every=1)
    # ConjugateGradient()
    # ConjugateGradient(eta=0.1, alphaguess=LineSearches.InitialQuadratic(), linesearch = LineSearches.StrongWolfe())
)
ğš¯_min = vector_to_array(result.minimizer)

X_test = X[40001:42000, :]
Y_test = Y[40001:42000]
y_pred = [predict(X_test[i, :], ğš¯_min) for i in 1:length(Y_test)]
@show mean(y_pred .!= d[40001:42000, 1])
=#

# NLopt
# function f(x, grad)
#     grad = Î”J(x)
#     return J(x)
# end
#
# opt = Opt(:LD_MMA, (length(init_Î¸1) + length(init_Î¸2)))
# opt.min_objective = f
#
# (minf,minx,ret) = optimize(opt, array_to_vector([init_Î¸1, init_Î¸2]))
#

# check gradient
L1 = 3
L2 = 3
L3 = 3
m = 5
X_train = reshape(rand(m*L1), m, L1)
Y_train = map(x->transform_digit_to_bitvec(x, 3), rand(0:2, m))
init_Î¸1 = reshape(
    rand(Distributions.Uniform(-Ïµ, Ïµ), (L1 + 1) * L2),
    L2,
    (L1 + 1),
) # L2 x L1
init_Î¸2 = reshape(
    rand(Distributions.Uniform(-Ïµ, Ïµ), (L2 + 1) * L3),
    L3,
    (L2 + 1),
) # L3 x L2

function checkGradient(ğš¯)
    Ïµ = 1e-4
    numgrad = zeros(size(ğš¯))
    perturb = zeros(size(ğš¯))
    for i in 1:length(ğš¯)
        perturb[i] = Ïµ
        numgrad[i] = (J(vector_to_array(ğš¯ + perturb)) - J(vector_to_array(ğš¯ - perturb))) / (2*Ïµ)
        perturb[i] = 0
    end
    numgrad
end

numGrad = checkGradient(array_to_vector([init_Î¸1, init_Î¸2]))
propGrad = array_to_vector(Î”J([init_Î¸1, init_Î¸2]))
@test isapprox(numGrad, propGrad, atol=1e-9)
#

#= show test case
x_test = convert(Array, X[1, :])
@show y_hat = predict(x_test, ğš¯_min)
@show d[1, 1]

function image_digits(x)
    Gray.(reshape(x, 28, 28)')
end

image_digits(x_test)
=#
